/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/. */

#pragma once

// Local Includes
#include "videoplayer.h"

// External Includes
#include <component.h>
#include <rendercomponent.h>
#include <nap/resourceptr.h>
#include <rendertexture2d.h>
#include <planemesh.h>
#include <rendertarget.h>
#include <color.h>
#include <materialinstance.h>
#include <renderablemesh.h>

namespace nap
{
	// Forward Declares
	class RenderVideoComponentInstance;

	/**
	 * Renders the output of a nap::VideoPlayer directly to texture without having to define a render target, shader or mesh.
	 * This components converts the YUV textures, generated by the nap::VideoPlayer, into an RGB texture.
	 * Call draw() in your application render() call, in between nap::RenderService::beginHeadlessRecording() 
	 * and nap::RenderService::endHeadlessRecording().
	 * The video frame is scaled to fit the dimensions of the given output texture.
	 * It is still possible to render this component using the render service, although only orthographic cameras are supported.
	 */
	class NAPAPI RenderVideoComponent : public RenderableComponent
	{
		RTTI_ENABLE(RenderableComponent)
		DECLARE_COMPONENT(RenderVideoComponent, RenderVideoComponentInstance)
	public:
		ResourcePtr<VideoPlayer>		mVideoPlayer = nullptr;								///< Property: 'VideoPlayer' the video player to render to texture
		ResourcePtr<RenderTexture2D>	mOutputTexture = nullptr;							///< Property: 'OutputTexture' the RGB8 texture to render output to
		ERasterizationSamples			mRequestedSamples = ERasterizationSamples::One;		///< Property: 'Samples' The number of samples used during Rasterization. For better results enable 'SampleShading'
		RGBAColor8						mClearColor = { 255, 255, 255, 255 };				///< Property: 'ClearColor' the color that is used to clear the render target
	};


	/**
	 * Renders the output of a nap::VideoPlayer directly to texture without having to define a render target, shader or mesh.
	 * This components converts the YUV textures, generated by the nap::VideoPlayer, into an RGB texture.
	 * Call draw() in your application render() call, in between nap::RenderService::beginHeadlessRecording()
	 * and nap::RenderService::endHeadlessRecording().
	 * The video frame is scaled to fit the dimensions of the given output texture.
	 * It is still possible to render this component using the render service, although only orthographic cameras are supported.
	 */
	class NAPAPI RenderVideoComponentInstance : public RenderableComponentInstance
	{
		RTTI_ENABLE(RenderableComponentInstance)
	public:
		RenderVideoComponentInstance(EntityInstance& entity, Component& resource);

		/**
		 * Initializes the component based on resource.
		 * @param errorState contains the error if initialization fails.
		 * @return if initialization succeeded.
		 */
		virtual bool init(utility::ErrorState& errorState) override;

		/**
		 * Called by the Render Service. Only orthographic cameras are supported.
		 */
		virtual bool isSupported(nap::CameraComponentInstance& camera) const override;

		/**
		 * Returns the rendered RGB video texture.
		 * @return the rendered RGB video texture.
		 */
		Texture2D& getOutputTexture();

		/**
		 * Renders the output of a nap::VideoPlayer directly to texture.
		 * This components converts the YUV textures, generated by the nap::VideoPlayer, into an RGB texture.
		 * Call this in your application render() call, in between nap::RenderService::beginHeadlessRecording() and 
		 * nap::RenderService::endHeadlessRecording(). Do not call this function outside 
		 * of a headless recording pass, ie: when rendering to a window. 
		 * Alternatively, you can use the render service to render this component, see onDraw()
		 */
		void draw();

	protected:
		/**
		 * Draws the video frame full screen to the currently active render target,
		 * when the view matrix = identity.
		 * @param renderTarget the target to render to.
		 * @param commandBuffer the currently active command buffer.
		 * @param viewMatrix often the camera world space location
		 * @param projectionMatrix often the camera projection matrix
		*/
		virtual void onDraw(IRenderTarget& renderTarget, VkCommandBuffer commandBuffer, const glm::mat4& viewMatrix, const glm::mat4& projectionMatrix) override;

	private:
		VideoPlayer*				mPlayer = nullptr;								///< Video player to render	
		RenderTexture2D*			mOutputTexture = nullptr;						///< Texture currently bound by target
		RGBColorFloat				mClearColor = { 0.0f, 0.0f, 0.0f };				///< Target Clear Color
		RenderTarget				mTarget;										///< Target video is rendered into
		PlaneMesh					mPlane;											///< Plane that is rendered
		MaterialInstance			mMaterialInstance;								///< The MaterialInstance as created from the resource.
		MaterialInstanceResource	mMaterialInstanceResource;						///< Resource used to initialize the material instance
		RenderableMesh				mRenderableMesh;								///< Valid Plane / Material combination
		RenderService*				mRenderService = nullptr;						///< Pointer to the render service
		UniformMat4Instance*		mModelMatrixUniform = nullptr;					///< Model matrix uniform in the material
		UniformMat4Instance*		mProjectMatrixUniform = nullptr;				///< Projection matrix uniform in the material
		UniformMat4Instance*		mViewMatrixUniform = nullptr;					///< View matrix uniform in the material
		UniformStructInstance*		mMVPStruct = nullptr;							///< model view projection struct
		Sampler2DInstance*			mYSampler = nullptr;							///< Video material Y sampler
		Sampler2DInstance*			mUSampler = nullptr;							///< Video material U sampler
		Sampler2DInstance*			mVSampler = nullptr;							///< Video material V sampler
		glm::mat4x4					mModelMatrix;									///< Computed model matrix, used to scale plane to fit target bounds
		bool						mDirty = true;									///< If the model matrix needs to be re-computed

		/**
		 * Checks if the uniform is available on the source material and creates it if so
		 * @return the uniform, nullptr if not available.
		 */
		UniformMat4Instance* ensureUniform(const std::string& uniformName, utility::ErrorState& error);

		/**
		 * Checks if the sampler with the given name is available on the source material and creates it if so
		 * @return new or created sampler
		 */
		Sampler2DInstance* ensureSampler(const std::string& samplerName, utility::ErrorState& error);

		/**
		 * Called every time a new video is selected.
		 * Updates the YUV textures in the video material.
		 * @param player the video player that switched the video.
		 */
		void videoChanged(VideoPlayer& player);

		// Called when video selection changes
		nap::Slot<VideoPlayer&> mVideoChangedSlot = { this, &RenderVideoComponentInstance::videoChanged };
	};
}
